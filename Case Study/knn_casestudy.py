# -*- coding: utf-8 -*-
"""KNN_CaseStudy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TpYM3WvB7O098NvcdxgYCJdUBQdCjTD4
"""

import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

# Load the dataset with the correct delimiter
data = pd.read_csv('/content/winequality-red.csv', delimiter=';')

# Check the column names again
print(data.columns)

# Create a binary classification for wine quality
data['quality_label'] = data['quality'].apply(lambda x: 1 if x >= 7 else 0)

# Define features (X) and target (y)
X = data.drop(columns=['quality', 'quality_label'])  # features (drop 'quality')
y = data['quality_label']  # target

# Split data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize KNN with k=5
knn = KNeighborsClassifier(n_neighbors=5)

# Train the model
knn.fit(X_train, y_train)

# Make predictions
y_pred = knn.predict(X_test)

# Calculate accuracy manually
accuracy = sum(y_pred == y_test) / len(y_test)
print(f"Model Accuracy: {accuracy * 100:.2f}%")

